{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71d86082-05e2-43fc-89ad-ec5a1c0531a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import yaml\n",
    "import threading\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from collections import defaultdict\n",
    "from yacos.essential import Engine, IO\n",
    "from yacos.info import compy\n",
    "from yacos.info.compy.extractors import LLVMDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61ef143-0358-460e-8316-080bb19abced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the LLVM driver.\n",
    "driver = LLVMDriver()\n",
    "# Define the builder\n",
    "builder = compy.LLVMGraphBuilder(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b455cb-0d24-4b58-9756-0f1279190d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visitors = {\n",
    "    # Clang\n",
    "    'ast': compy.ASTVisitor,\n",
    "    'astdata': compy.ASTDataVisitor,\n",
    "    'astdatacfg': compy.ASTDataCFGVisitor,\n",
    "    # LLVM\n",
    "    'programl': compy.LLVMProGraMLVisitor,\n",
    "    'programlnoroot': compy.LLVMProGraMLNoRootVisitor,\n",
    "    'cfg': compy.LLVMCFGVisitor,\n",
    "    'cfgcompact': compy.LLVMCFGCompactVisitor,\n",
    "    'cfgcall': compy.LLVMCFGCallVisitor,\n",
    "    'cfgcallnoroot': compy.LLVMCFGCallNoRootVisitor,\n",
    "    'cfgcallcompact': compy.LLVMCFGCallCompactVisitor,\n",
    "    'cfgcallcompact1e': compy.LLVMCFGCallCompactOneEdgeVisitor,\n",
    "    'cfgcallcompactnoroot': compy.LLVMCFGCallCompactNoRootVisitor,\n",
    "    'cfgcallcompact1enoroot': compy.LLVMCFGCallCompactOneEdgeNoRootVisitor,\n",
    "    'cdfg': compy.LLVMCDFGVisitor,\n",
    "    'cdfgcompact': compy.LLVMCDFGCompactVisitor,\n",
    "    'cdfgcompact1e': compy.LLVMCDFGCompactOneEdgeVisitor,\n",
    "    'cdfgcall': compy.LLVMCDFGCallVisitor,\n",
    "    'cdfgcallnoroot': compy.LLVMCDFGCallNoRootVisitor,\n",
    "    'cdfgcallcompact': compy.LLVMCDFGCallCompactVisitor,\n",
    "    'cdfgcallcompact1e': compy.LLVMCDFGCallCompactOneEdgeVisitor,\n",
    "    'cdfgcallcompactnoroot': compy.LLVMCDFGCallCompactNoRootVisitor,\n",
    "    'cdfgcallcompact1enoroot': compy.LLVMCDFGCallCompactOneEdgeNoRootVisitor,\n",
    "    'cdfgplus': compy.LLVMCDFGPlusVisitor,\n",
    "    'cdfgplusnoroot': compy.LLVMCDFGPlusNoRootVisitor\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8875d2-8fc1-4ac3-94b4-a49b5adabd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5000 directories\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/home/nonroot/experiment/datasets/classify_seqs/group1.1000/'\n",
    "folders = glob.glob(f\"{dataset_dir}/*/*/\")\n",
    "print(f\"There are {len(folders)} directories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5611656c-1589-4882-ac70-26ce049edf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '/home/nonroot/experiment/results/notebook/'\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "016684a1-009e-4907-a2cc-69c767ecddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_graph_data(graph, graph_type):\n",
    "    \"\"\"Convert the graph to StellarGraph representation.\"\"\"\n",
    "\n",
    "    nodes = {}\n",
    "\n",
    "    if 'ast' in graph_type:\n",
    "        nodes['w2v'] = graph.get_nodes_word2vec_embeddings('ast')\n",
    "        nodes['boo'] = graph.get_nodes_bag_of_words_embeddings('ast')\n",
    "    elif 'asm' in graph_type:\n",
    "        nodes['boo'] = graph.get_nodes_bag_of_words_embeddings('ir')\n",
    "    else:\n",
    "        nodes['w2v'] = graph.get_nodes_word2vec_embeddings('ir')\n",
    "        nodes['boo'] = graph.get_nodes_bag_of_words_embeddings('ir')\n",
    "        nodes['i2v'] = graph.get_nodes_inst2vec_embeddings()\n",
    "        nodes['ir2v'] = graph.get_nodes_ir2vec_embeddings()\n",
    "\n",
    "    edges = graph.get_edges_dataFrame()\n",
    "\n",
    "    return edges, nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a477519-ddb0-461d-b7dc-e1321071752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_extract_info(benchdir, optname, optseq):\n",
    "    d = dict()\n",
    "    try:\n",
    "        Engine.cleanup(benchdir, 'opt')\n",
    "        Engine.compile(benchdir, 'opt', optseq)\n",
    "        binsize = IO.load_yaml(os.path.join(benchdir, 'binary_size.yaml'))\n",
    "        codesize = IO.load_yaml(os.path.join(benchdir, 'code_size.yaml'))\n",
    "        compiletime = IO.load_yaml(os.path.join(benchdir, 'compile_time.yaml'))       \n",
    "        d.update(binsize)\n",
    "        d.update(codesize)\n",
    "        d.update(compiletime)\n",
    "        return d\n",
    "    except BaseException as e:\n",
    "        print(f\"Error compiling benchmark at {benchdir} with {optname}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def compile_bench_with_candidates(benchdir: str, opt: list, optname: str, output_prefix: str, results_dir: str):\n",
    "    # benchdir = random.choice(folders)\n",
    "    # optname = random.choice(list(optimization_seqs.keys()))\n",
    "    class_results = []\n",
    "    #print(f\"Processing: {optname}....\")\n",
    "        \n",
    "    # Last one will be without any additional candidate (original)\n",
    "    for i, cand in enumerate(candidates):\n",
    "        new_opt = opt + cand\n",
    "        new_opt_str = ' '.join(new_opt)\n",
    "        new_optname = f'{optname}:{\"+\".join(cand)}'\n",
    "        result = compile_and_extract_info(benchdir, new_optname, new_opt_str)\n",
    "        if not result:\n",
    "            print(f\"Discarding {benchdir} with optseq={new_opt_str} and (optname={optname})\")\n",
    "            return None\n",
    "        \n",
    "        result['opt'] = new_opt\n",
    "        result['optname'] = new_optname\n",
    "        class_results.append(result)\n",
    "    \n",
    "    # Compile with no additional candidates\n",
    "    opt_str = ' '.join(opt)\n",
    "    result = compile_and_extract_info(benchdir, optname, opt_str)\n",
    "    if not result:\n",
    "        print(f\"Discarding {benchdir} with optseq={new_opt_str} and (optname={optname})\")\n",
    "        return None\n",
    "    \n",
    "    # Let's save the class results\n",
    "    output_filename = os.path.join(results_dir, f\"{output_prefix}_classes.yaml\")\n",
    "    IO.dump_yaml(class_results, output_filename)\n",
    "    #print(f\"Saved classes to {output_filename}\")\n",
    "    \n",
    "    # Now lets generate the representation!\n",
    "    try:\n",
    "        source = f'{benchdir}/a.out_o.bc'\n",
    "        extinfo = builder.ir_to_info(source)\n",
    "    except BaseException as e:\n",
    "        print(f\"Error extracting IR from {source}: {e}\")\n",
    "        return None\n",
    "            \n",
    "    for rep in representations:\n",
    "        try:\n",
    "            graph = builder.info_to_representation(extinfo, visitors[rep])\n",
    "            edges, nodes = extract_graph_data(graph, rep)\n",
    "            for extname, extdata in nodes.items():\n",
    "                output_filename = os.path.join(results_dir, f\"{output_prefix}_{extname}\")     \n",
    "                np.savez_compressed(output_filename, edges=edges, nodes=extdata, labels=result)\n",
    "            #print(f\"Representation {rep} extracted for {benchdir}\")\n",
    "        except BaseException as e:\n",
    "            print(f\"Error extracting representation {rep} for {benchdir}: {e}\")\n",
    "            continue\n",
    "            \n",
    "    return class_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c6bc550-9d37-42e8-b604-a919ea5cb869",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_748941/1516868846.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mexp_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'5opts-5000'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mfinal_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mok_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "optimization_seqs = {\n",
    "    '500-bSum':  [\n",
    "        '-mem2reg', '-jump-threading', '-instcombine', '-early-cse-memssa', '-jump-threading', '-licm', '-early-cse-memssa', \n",
    "        '-sroa', '-simplifycfg', '-reassociate', '-instcombine', '-slp-vectorizer', '-early-cse-memssa'\n",
    "    ],\n",
    "    '4372-bMed': [\n",
    "        '-mem2reg', '-early-cse-memssa', '-correlated-propagation', '-instcombine', '-reassociate', '-simplifycfg', \n",
    "        '-early-cse-memssa', '-instcombine', '-licm', '-jump-threading', '-simplifycfg', '-dse', '-reassociate', \n",
    "        '-early-cse-memssa', '-instcombine'\n",
    "    ],\n",
    "    '5624-bLim': [\n",
    "        '-sroa', '-early-cse-memssa', '-reassociate', '-instcombine', '-simplifycfg', '-licm', '-speculative-execution', \n",
    "        '-jump-threading', '-early-cse-memssa', '-simplifycfg', '-instcombine', '-simplifycfg'\n",
    "    ],\n",
    "    '6310-bGeo': [\n",
    "        '-loop-vectorize', '-sroa', '-gvn', '-instcombine', '-simplifycfg', '-instcombine', '-licm', '-gvn', \n",
    "        '-correlated-propagation', '-jump-threading', '-mldst-motion', '-early-cse-memssa', '-instcombine', \n",
    "        '-simplifycfg' '-instsimplify'\n",
    "    ],\n",
    "    '4211-bCap': [\n",
    "        '-loop-rotate', '-sroa', '-correlated-propagation', '-indvars', '-gvn', '-tailcallelim', '-instcombine', \n",
    "        '-jump-threading', '-reassociate', '-instcombine', '-early-cse-memssa'\n",
    "    ]\n",
    "}\n",
    "\n",
    "candidates = [\n",
    "    ['-simplifycfg'],\n",
    "    ['-instcombine'],\n",
    "    ['-early-cse-memssa'],\n",
    "    ['-gvn'],\n",
    "    ['-sroa'],\n",
    "    #['-jump-threading'],\n",
    "    #['-mem2reg'],\n",
    "    #['-licm'],\n",
    "]\n",
    "\n",
    "representations = [\n",
    "    'cfgcompact',\n",
    "    #'cfgcallcompact',\n",
    "    # 'cfgcallcompact1e',\n",
    "    'cfgcallcompactnoroot',\n",
    "    'cfgcallcompact1enoroot',\n",
    "   # 'cdfgcompact',\n",
    "   # 'cdfgcompact1e',\n",
    "   # 'cdfgcallcompact',\n",
    "   # 'cdfgcallcompact1e',\n",
    "   # 'cdfgcallcompactnoroot',\n",
    "   # 'cdfgcallcompact1enoroot'\n",
    "]\n",
    "\n",
    "class_programs = 5000\n",
    "label = 'binary_size'\n",
    "min_passes = 0\n",
    "tolerance = 1000000\n",
    "equals = 0\n",
    "totals = 0\n",
    "exhausteds = 0\n",
    "class_counts = {i: 0 for i, _ in enumerate(candidates)}\n",
    "not_oks = 0\n",
    "exists = 0\n",
    "\n",
    "exp_id = '5opts-5000'\n",
    "final_dir = os.path.join(results_dir, exp_id)\n",
    "os.makedirs(final_dir, exist_ok=True)\n",
    "ok_files = []\n",
    "\n",
    "threads_running = True\n",
    "\n",
    "def monitoring(interval: float = 30.0):\n",
    "    global threads_running, class_programs, class_counts, not_oks, equals, exhausteds, tolerance, totals, candidates, exists\n",
    "    while threads_running:\n",
    "        oks = sum(list(class_counts.values()))\n",
    "        max_oks = class_programs*len(candidates)\n",
    "        samples_per_class = {' '.join(candidates[k]): v for k, v in class_counts.items()}\n",
    "        output_dict = {\n",
    "            'Number of sampes per class': {\n",
    "                ' '.join(candidates[k]): v\n",
    "                for k, v in class_counts.items()\n",
    "            },\n",
    "            '[DISCARDED] Total': not_oks,\n",
    "            '[DISCARDED] Samples with repeated minimum sizes': equals,\n",
    "            '[DISCARDED] Compiled the app with same optimization passes': exists,\n",
    "            '[DISCARDED] With maximum number of samples': exhausteds,\n",
    "            'Total tested so far': totals,\n",
    "            'Total tested so far (%)': (oks/max_oks)*100,\n",
    "            'Tolerance': tolerance,\n",
    "            'Tolerance (%)': (totals/tolerance)*100,\n",
    "        }\n",
    "        output_dict_str = yaml.dump(output_dict, indent=4, default_flow_style=False)\n",
    "        print(f\"[{str(datetime.datetime.now())}] \" +\n",
    "              f\"Samples per class: {samples_per_class}; Repeated minimuns: {equals}; Repeated opts: {exists}; Samples exhausted: {exhausteds}; \" +\n",
    "              f\"Total: {totals} ({(oks/max_oks)*100:.3f}); Tolerance: {tolerance} ({(totals/tolerance)*100:.3f})\")\n",
    "        time.sleep(interval)\n",
    "\n",
    "def run():\n",
    "    global threads_running, class_programs, label, min_passes, tolerance, class_counts, not_oks, exp_id, final_dir, equals, exhausteds, totals, exists, ok_files\n",
    "    print(f\"Started thread: {threading.current_thread().name}....\")\n",
    "    while threads_running:\n",
    "        #print(f\"COUNTS: {class_counts}\")\n",
    "        if not_oks > tolerance:\n",
    "            print(\"Tolerance reached!\")\n",
    "            print(f\"Classes BEST: {class_counts}\")\n",
    "            threads_running = False\n",
    "            break    \n",
    "\n",
    "        finished = True\n",
    "        for count in class_counts.values():\n",
    "            if count < class_programs:\n",
    "                finished = False\n",
    "                break\n",
    "\n",
    "        if finished:\n",
    "            print(f\"Finished. Counts: {class_counts}\")\n",
    "            threads_running = False\n",
    "            break\n",
    "\n",
    "        benchdir = random.choice(folders)\n",
    "        optname = random.choice(list(optimization_seqs.keys()))\n",
    "        outfilename = benchdir[len(dataset_dir):-1].replace('/', '.')\n",
    "        cut_index = random.choice(range(min_passes, len(optimization_seqs[optname])))\n",
    "        opt = optimization_seqs[optname][:cut_index]\n",
    "        optname = f\"{optname}:{cut_index}\"\n",
    "        output_prefix = f\"{outfilename}_{optname}\"\n",
    "        if os.path.exists(os.path.join(final_dir, f\"{output_prefix}_classes.yaml\")):\n",
    "            print(f\"Skipping {output_prefix}... Already exists.\")\n",
    "            exists += 1\n",
    "            not_oks += 1\n",
    "            continue\n",
    "\n",
    "        class_results = compile_bench_with_candidates(benchdir, opt, optname, output_prefix, final_dir)\n",
    "        if not class_results:\n",
    "            not_oks += 1\n",
    "            continue\n",
    "        results = [r[label] for r in class_results]\n",
    "        totals += 1\n",
    "        min_label = min(results)\n",
    "        min_label_indexes = [r==min_label for r in results]\n",
    "        # print(f\"RESULTS: {results}, min_label: {min_label}, min_label_indexes: {min_label_indexes}\")\n",
    "        if len([r for r in min_label_indexes if r]) > 1:\n",
    "            # print(f\"There are repeated minumums ({len(min_label_indexes)})! Skipping\")\n",
    "            equals += 1\n",
    "            not_oks += 1\n",
    "            # may remove files...\n",
    "            continue\n",
    "\n",
    "        best_index = min_label_indexes.index(True)\n",
    "        class_counts[best_index] += 1   \n",
    "        if class_counts[best_index] > class_programs:\n",
    "            # print(f\"Class {best_index} is exahusted ({class_counts[best_index]})! Skipping\")\n",
    "            exhausteds += 1\n",
    "            not_oks += 1\n",
    "            continue\n",
    "\n",
    "        ok_files.append(output_prefix)\n",
    "        # print(f\"OK ({best_index})\")\n",
    "\n",
    "num_workers = 7\n",
    "start = time.time()\n",
    "threads = [threading.Thread(target=run, name=f'Extractor {i}') for i in range(num_workers)]\n",
    "threads.append(threading.Thread(target=monitoring, name='Monitor'))\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "end = time.time()\n",
    "\n",
    "IO.dump_yaml(ok_files, os.path.join(final_dir, \"info.yaml\"))\n",
    "print(f\"CLASS Counts: {class_counts}\")\n",
    "print(f\"It took {end-start} seconds...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d8083e-e1f0-4aca-ad15-2664f2c68905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
