{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfLOnT3CoFrf"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05gcTZ7GoLMY"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import time\n",
        "import yaml as yl\n",
        "import pickle as pk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsKRcrjGoO8_"
      },
      "source": [
        "**Tensorflow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbhHTBIlpmkE"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Conv1D, MaxPool2D, MaxPool1D, Dropout, Flatten\n",
        "from tensorflow.keras.losses import categorical_crossentropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhv8cqZgp6cM"
      },
      "source": [
        "**Profiler**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h58BOcwIp8iv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2457bc0-ad1b-41fa-8984-14deac6b43ba"
      },
      "source": [
        "#%pip install line_profiler\n",
        "%pip install memory_profiler\n",
        "%pip install wandb\n",
        "\n",
        "#import line_profiler\n",
        "%load_ext memory_profiler\n",
        "#import wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: memory_profiler in /usr/local/lib/python3.7/dist-packages (0.58.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.18)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.1)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "The memory_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext memory_profiler\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iCBIg3LqF9j"
      },
      "source": [
        "**Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt0pBim4J5Rj"
      },
      "source": [
        "def execute(cmdline):\n",
        "  \"\"\"Execute a command.\"\"\"\n",
        "  try:\n",
        "    ret = subprocess.run(cmdline,\n",
        "                        shell=True,\n",
        "                        check=True,\n",
        "                        capture_output=True)\n",
        "  except subprocess.CalledProcessError:\n",
        "    print('Execute: {}'.format(cmdline))\n",
        "    return ''\n",
        "\n",
        "  return ret.stdout.decode(), ret.stderr.decode()\n",
        "\n",
        "def save(filename, data):\n",
        "  \"\"\"Save a file.\"\"\"\n",
        "  fout = open(filename, 'w')\n",
        "  fout.write(data)\n",
        "  fout.close()\n",
        "\n",
        "def random_features(sequence):\n",
        "  \"\"\"Create random features.\"\"\"\n",
        "  new_sequence = np.random.random(sequence.shape)\n",
        "  return new_sequence\n",
        "\n",
        "def zero_to_random_features(sequence):\n",
        "  \"\"\"\"Transform 0 in a random number.\"\"\"\n",
        "  new_sequence = np.copy(sequence)\n",
        "  new_sequence[new_sequence == 0] = np.random.random()\n",
        "  return new_sequence\n",
        "\n",
        "def one_to_random_features(sequence):\n",
        "  \"\"\"\"Transform 1 in a random number.\"\"\"\n",
        "  new_sequence = np.copy(sequence)\n",
        "  new_sequence[new_sequence == 1] = np.random.random()\n",
        "  return new_sequence\n",
        "\n",
        "def create_model(labels, input_shape, model_type='v1'):\n",
        "  model = Sequential()\n",
        "\n",
        "  if model_type == 'v1_1d':\n",
        "    model.add(Conv1D(filters=512, kernel_size=2, activation=\"relu\", padding='same', input_shape=input_shape))\n",
        "    model.add(Dense(units=512, activation=\"relu\"))\n",
        "    model.add(MaxPool1D())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(labels, activation = 'sigmoid'))\n",
        "  elif model_type == 'v2_1d':\n",
        "    model.add(Conv1D(filters=16, kernel_size=3, activation=\"relu\", padding='same', input_shape=input_shape))\n",
        "    model.add(MaxPool1D(pool_size=2))\n",
        "    model.add(Conv1D(filters=32, kernel_size=5, activation=\"relu\", padding='same'))\n",
        "    model.add(MaxPool1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=128, activation=\"relu\"))\n",
        "    model.add(Dropout(rate=0.5))\n",
        "    model.add(Dense(units=labels, activation = 'sigmoid'))\n",
        "  elif model_type == 'v1_2d':\n",
        "    model.add(Conv2D(filters=512, kernel_size=(2, 2), activation=\"relu\", padding='same', input_shape=input_shape))\n",
        "    model.add(Dense(units=512, activation=\"relu\"))\n",
        "    model.add(MaxPool2D())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(labels, activation = 'sigmoid'))\n",
        "  elif model_type == 'v2_2d':\n",
        "    model.add(Conv2D(filters=16, kernel_size=(3, 3), activation=\"relu\", padding='same', input_shape=input_shape))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(5, 5), activation=\"relu\", padding='same'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=128, activation=\"relu\"))\n",
        "    model.add(Dropout(rate=0.5))\n",
        "    model.add(Dense(units=labels, activation = 'sigmoid'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9MTLD1djY3l"
      },
      "source": [
        "**Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4AqVescjcvB"
      },
      "source": [
        "# Google Driver\n",
        "FLAGS_driver = '/content/drive'\n",
        "\n",
        "# Train data ratio\n",
        "FLAGS_train_ratio = 0.75\n",
        "\n",
        "# Validation data ratio\n",
        "FLAGS_val_ratio = 0.25\n",
        "\n",
        "# Test data ratio\n",
        "FLAGS_test_ratio = 0.20\n",
        "\n",
        "# Number of epochs\n",
        "FLAGS_epochs = 100\n",
        "\n",
        "# Verbose\n",
        "FLAGS_training_verbose = 1\n",
        "\n",
        "# Store the results?\n",
        "FLAGS_store_results = True\n",
        "\n",
        "# Store the model?\n",
        "FLAGS_store_model = False\n",
        "\n",
        "# Store Wandb data?\n",
        "FLAGS_store_wandb = False\n",
        "\n",
        "# Wandb project name\n",
        "FLAGS_project_name = 'bestseqssblp_200'\n",
        "\n",
        "# Breakdown the runtime\n",
        "FLAGS_times = {}\n",
        "\n",
        "# Dataset\n",
        "#\n",
        "# classifyapp/Oz\n",
        "# classifyapp/Oz\n",
        "# bestseqssblp/O0/group1.1000\n",
        "#\n",
        "FLAGS_dataset = 'bestseqssblp2021.poj/200/Oz'\n",
        "\n",
        "# Result directory\n",
        "#\n",
        "# classifyapp/POJ-104\n",
        "FLAGS_r_d_name = 'bestseqssblp_200'\n",
        "\n",
        "# Result directory suffix\n",
        "FLAGS_suffix = ''\n",
        "\n",
        "# Model\n",
        "FLAGS_model = 'v2_1d'\n",
        "\n",
        "# Source ratio (use all data?)\n",
        "#\n",
        "# It is not possible to use all POJ dataset in Colab (error -> out of memory).\n",
        "# It is possible to load 450 sources (90%) per group.\n",
        "#\n",
        "# POJ ratios -> 0.9, 0.45, 0.09\n",
        "FLAGS_source_ratio = 1.0\n",
        "\n",
        "# Filter source data\n",
        "FLAGS_filter_source = False\n",
        "\n",
        "# Number of labels\n",
        "#\n",
        "# POJ labels -> 104, 52, 10\n",
        "FLAGS_labels = 11\n",
        "\n",
        "# Features type: random, zero to random, one to random\n",
        "FLAGS_features = 'all_features'\n",
        "\n",
        "# Round\n",
        "FLAGS_round = 'round3'\n",
        "\n",
        "# Random state\n",
        "FLAGS_random_state = {'round1': 123456789, 'round2': 12345678, 'round3': 1234567}\n",
        "\n",
        "# Sequence\n",
        "#\n",
        "# inst2vec.2d -> O0\n",
        "# ir2vec.instructions (2d)\n",
        "FLAGS_sequence = 'ir2vec.program'\n",
        "\n",
        "# Results directory\n",
        "last = '{}_{}_{}'.format(FLAGS_features, FLAGS_labels, FLAGS_source_ratio) if not FLAGS_suffix else '{}_{}_{}'.format(FLAGS_features, FLAGS_labels, FLAGS_source_ratio, FLAGS_suffix)\n",
        "FLAGS_results_directory = os.path.join(FLAGS_driver,\n",
        "                                       'My Drive/classification/{}'.format(FLAGS_r_d_name),\n",
        "                                       FLAGS_round,\n",
        "                                       FLAGS_sequence,\n",
        "                                       last)\n",
        "# Dataset directory\n",
        "FLAGS_dataset_directory = os.path.join(FLAGS_sequence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbxHHwngACel"
      },
      "source": [
        "**Import the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40kx7ji0AH1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e194a25d-776b-483a-fb48-ea0a7ccd21fa"
      },
      "source": [
        "#\n",
        "# Cleanup\n",
        "#\n",
        "command = 'rm -rf {}* gpu.log gpu_usage.sh graphs-number-of-nodes.yaml'.format(FLAGS_sequence)\n",
        "!$command\n",
        "\n",
        "#\n",
        "# Dataset\n",
        "#\n",
        "wget = 'wget www.csl.uem.br/repository/data/{}/{}.tar.xz'.format(FLAGS_dataset, FLAGS_sequence)\n",
        "tar = 'tar xfJ {}.tar.xz'.format(FLAGS_sequence)\n",
        "!$wget\n",
        "!$tar\n",
        "\n",
        "if FLAGS_filter_source:\n",
        "  # \n",
        "  # Graphs' number of nodes (to filter data)\n",
        "  #\n",
        "  wget = 'wget www.csl.uem.br/repository/data/{}/graphs-number-of-nodes.yaml'.format(FLAGS_dataset)\n",
        "  !$wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-24 22:14:44--  http://www.csl.uem.br/repository/data/bestseqssblp2021.poj/200/Oz/ir2vec.program.tar.xz\n",
            "Resolving www.csl.uem.br (www.csl.uem.br)... 186.233.153.209\n",
            "Connecting to www.csl.uem.br (www.csl.uem.br)|186.233.153.209|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.csl.uem.br/repository/data/bestseqssblp2021.poj/200/Oz/ir2vec.program.tar.xz [following]\n",
            "--2021-08-24 22:14:45--  https://www.csl.uem.br/repository/data/bestseqssblp2021.poj/200/Oz/ir2vec.program.tar.xz\n",
            "Connecting to www.csl.uem.br (www.csl.uem.br)|186.233.153.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5145668 (4.9M) [application/octet-stream]\n",
            "Saving to: ‘ir2vec.program.tar.xz’\n",
            "\n",
            "ir2vec.program.tar. 100%[===================>]   4.91M   781KB/s    in 12s     \n",
            "\n",
            "2021-08-24 22:14:59 (417 KB/s) - ‘ir2vec.program.tar.xz’ saved [5145668/5145668]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrJz5i5Gyq8v"
      },
      "source": [
        "**Background Monitor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCRgX8x5xzpX"
      },
      "source": [
        "!rm -f gpu.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfgikNwqxx8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6316ad6-99b4-4fa7-8778-a8447938fc6c"
      },
      "source": [
        "%%writefile gpu_usage.sh\n",
        "#! /bin/bash\n",
        "#comment: run for 24 hours, change it as per your use\n",
        "end=$((SECONDS+86400))\n",
        "\n",
        "while [ $SECONDS -lt $end ]; do\n",
        "    nvidia-smi --format=csv --query-gpu=power.draw,utilization.gpu,memory.used,memory.free,fan.speed,temperature.gpu >> gpu.log\n",
        "    #comment: or use below command and comment above using #\n",
        "    #nvidia-smi dmon -i 0 -s mu -d 1 -o TD >> gpu.log\n",
        "done"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing gpu_usage.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN38KY13yG2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9aadd61-7bca-4fca-ba4f-22c1b5acb9f5"
      },
      "source": [
        "%%bash --bg\n",
        "\n",
        "bash gpu_usage.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 4 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIvRzT4mqI3e"
      },
      "source": [
        "**Open Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt6MwMNNqNXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6444b003-59dd-4f25-c92a-8c2d438ecf8f"
      },
      "source": [
        "if FLAGS_store_results:\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xccaNp8obm1a"
      },
      "source": [
        "**Initiate Wandb**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSyfMH6ebqAt"
      },
      "source": [
        "if FLAGS_store_wandb:\n",
        "  PROJECT_NAME = '{}_{}_{}_{}'.format(FLAGS_project_name,\n",
        "                                      FLAGS_round,\n",
        "                                      FLAGS_sequence,\n",
        "                                      '{}_{}'.format(FLAGS_labels,\n",
        "                                                      FLAGS_source_ratio)\n",
        "                                     )\n",
        "  wandb.init(project=PROJECT_NAME, entity='andersonfaustino')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XwBQyf7auFe"
      },
      "source": [
        "**Load the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8k6aYBimBlr"
      },
      "source": [
        "X = []\n",
        "Y = [] \n",
        "\n",
        "start = time.time()\n",
        "\n",
        "if FLAGS_filter_source:\n",
        "\n",
        "  for label in range(1, FLAGS_labels+1):\n",
        "    sources = graphs_size[label]\n",
        "    sources.sort()\n",
        "    \n",
        "    nof_sources = int(len(sources) * FLAGS_source_ratio)  \n",
        "\n",
        "    for i, source in enumerate(sources):\n",
        "      try:\n",
        "        filename = '{}/{}/{}.npz'.format(FLAGS_dataset_directory, label, source[1])\n",
        "        sequence = np.load(filename)\n",
        "      except:\n",
        "        print('Erro load', FLAGS_dataset_directory, label, source[1], flush=True)\n",
        "        continue\n",
        "      \n",
        "      sequence = sequence['values']\n",
        "      if FLAGS_features == 'random_features':\n",
        "        sequence = random_features(sequence)\n",
        "      elif FLAGS_features == 'zero_to_random_features':\n",
        "        seauence = zero_to_random_features(sequence)\n",
        "      elif FLAGS_features == 'one_to_random_features':\n",
        "        sequence = one_to_random_features(sequence) \n",
        "\n",
        "      Y.append(label-1)\n",
        "      X.append(sequence)\n",
        "\n",
        "      if i == nof_sources - 1:\n",
        "        break\n",
        "\n",
        "else:\n",
        "\n",
        "  for label in range(1, FLAGS_labels+1):\n",
        "    sources = glob.glob('{}/{}/*.npz'.format(FLAGS_dataset_directory, label))   \n",
        "\n",
        "    nof_sources = int(len(sources) * FLAGS_source_ratio)  \n",
        "\n",
        "    for i, source in enumerate(sources):\n",
        "      try:\n",
        "        sequence = np.load(source)\n",
        "      except:\n",
        "        print('Erro load', source, flush=True)\n",
        "        continue\n",
        "\n",
        "      sequence = sequence['values']\n",
        "      if FLAGS_features == 'random_features':\n",
        "        sequence = random_features(sequence)\n",
        "      elif FLAGS_features == 'zero_to_random_features':\n",
        "        sequence = zero_to_random_features(sequence)\n",
        "      elif FLAGS_features == 'one_to_random_features':\n",
        "        sequence = one_to_random_features(sequence) \n",
        "\n",
        "      Y.append(label-1)\n",
        "      X.append(sequence)\n",
        "\n",
        "      if i == nof_sources - 1:\n",
        "        break\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "FLAGS_times['loading'] = end - start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK7RNtafl0mN"
      },
      "source": [
        "**Dataset statistics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9LwAbhDl4S-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3072b6c-2bc4-4de4-b7c2-452480b3d889"
      },
      "source": [
        "stat_labels = pd.Series(Y, name='label', dtype=\"category\")\n",
        "print('\\n', stat_labels.value_counts().to_frame(), flush=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "     label\n",
            "10    200\n",
            "9     200\n",
            "8     200\n",
            "7     200\n",
            "6     200\n",
            "5     200\n",
            "4     200\n",
            "3     200\n",
            "2     200\n",
            "1     200\n",
            "0     200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woargju4WJ-J"
      },
      "source": [
        "**Prepare the dataaset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qigFBx3-lIDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068958e1-170c-41ed-c937-5bffc72778af"
      },
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "if '1d' in FLAGS_model:\n",
        "  X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "elif '2d' in FLAGS_model:\n",
        "  rows = X[0].shape[0]\n",
        "  cols = X[0].shape[1]\n",
        "  X = X.reshape(X.shape[0], rows, cols, 1)\n",
        "else:\n",
        "  print('Error: model does not exist.')\n",
        "  sys.exit(1)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X,\n",
        "                                                                    Y, \n",
        "                                                                    train_size=1.0-FLAGS_test_ratio,\n",
        "                                                                    test_size=FLAGS_test_ratio,\n",
        "                                                                    random_state=FLAGS_random_state[FLAGS_round])\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = model_selection.train_test_split(X_train,\n",
        "                                                                  Y_train,\n",
        "                                                                  train_size=FLAGS_train_ratio,\n",
        "                                                                  test_size=FLAGS_val_ratio,\n",
        "                                                                  random_state=FLAGS_random_state[FLAGS_round])\n",
        "\n",
        "print('Training:', X_train.shape[0], flush=True)\n",
        "print('Validation:', X_val.shape[0], flush=True)\n",
        "print('Test:', X_test.shape[0], flush=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: 1320\n",
            "Validation: 440\n",
            "Test: 440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-61I4RgZ5gj"
      },
      "source": [
        "**Create the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co-j9Rj4Z707",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece8c27a-9fbf-44f9-8ac2-89bf99ec909a"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "print(input_shape)\n",
        "model = create_model(FLAGS_labels, input_shape, FLAGS_model)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300, 1)\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_4 (Conv1D)            (None, 300, 16)           64        \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 150, 16)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 150, 32)           2592      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 75, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2400)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               307328    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 11)                1419      \n",
            "=================================================================\n",
            "Total params: 311,403\n",
            "Trainable params: 311,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9zn2-s6V681"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udFCunxrV-qK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5c64f47-98aa-46ba-8e41-2bab48b46e0f"
      },
      "source": [
        "start = time.time()\n",
        "%memit history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=50, epochs=FLAGS_epochs, verbose=FLAGS_training_verbose, shuffle=True)\n",
        "end = time.time()\n",
        "\n",
        "FLAGS_times['training'] = end - start"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "27/27 [==============================] - 1s 15ms/step - loss: 2.4969 - accuracy: 0.1470 - val_loss: 2.1378 - val_accuracy: 0.3273\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2.1087 - accuracy: 0.2614 - val_loss: 1.9508 - val_accuracy: 0.2932\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 2.0166 - accuracy: 0.3045 - val_loss: 1.8327 - val_accuracy: 0.4318\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1.8991 - accuracy: 0.3508 - val_loss: 1.7391 - val_accuracy: 0.4682\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 1.8202 - accuracy: 0.3947 - val_loss: 1.6562 - val_accuracy: 0.4841\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1.7471 - accuracy: 0.4212 - val_loss: 1.5456 - val_accuracy: 0.6205\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1.6546 - accuracy: 0.4636 - val_loss: 1.4937 - val_accuracy: 0.5432\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1.5927 - accuracy: 0.4970 - val_loss: 1.4339 - val_accuracy: 0.6318\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1.5384 - accuracy: 0.5068 - val_loss: 1.3471 - val_accuracy: 0.6727\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1.4801 - accuracy: 0.5212 - val_loss: 1.2850 - val_accuracy: 0.6795\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1.4152 - accuracy: 0.5492 - val_loss: 1.2418 - val_accuracy: 0.6932\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1.3990 - accuracy: 0.5720 - val_loss: 1.1772 - val_accuracy: 0.7409\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1.3354 - accuracy: 0.5864 - val_loss: 1.1361 - val_accuracy: 0.7545\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1.3051 - accuracy: 0.6030 - val_loss: 1.1133 - val_accuracy: 0.7341\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1.2838 - accuracy: 0.6152 - val_loss: 1.0781 - val_accuracy: 0.7705\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1.2324 - accuracy: 0.6182 - val_loss: 1.0220 - val_accuracy: 0.7841\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1.2130 - accuracy: 0.6311 - val_loss: 1.0216 - val_accuracy: 0.7523\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1.1494 - accuracy: 0.6591 - val_loss: 0.9643 - val_accuracy: 0.7659\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1.1152 - accuracy: 0.6674 - val_loss: 0.9086 - val_accuracy: 0.7977\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1.0964 - accuracy: 0.6818 - val_loss: 0.8929 - val_accuracy: 0.7909\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 1.0139 - accuracy: 0.7121 - val_loss: 0.8700 - val_accuracy: 0.7909\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1.0290 - accuracy: 0.7030 - val_loss: 0.8822 - val_accuracy: 0.8023\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 1.0085 - accuracy: 0.7212 - val_loss: 0.8111 - val_accuracy: 0.8205\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.9773 - accuracy: 0.6985 - val_loss: 0.8127 - val_accuracy: 0.8114\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.9674 - accuracy: 0.7212 - val_loss: 0.7599 - val_accuracy: 0.8159\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.9596 - accuracy: 0.7167 - val_loss: 0.7565 - val_accuracy: 0.8091\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.9346 - accuracy: 0.7250 - val_loss: 0.7340 - val_accuracy: 0.8182\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.8818 - accuracy: 0.7386 - val_loss: 0.7171 - val_accuracy: 0.7955\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.9062 - accuracy: 0.7356 - val_loss: 0.6785 - val_accuracy: 0.8364\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.8616 - accuracy: 0.7424 - val_loss: 0.6969 - val_accuracy: 0.8273\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.8401 - accuracy: 0.7530 - val_loss: 0.6635 - val_accuracy: 0.8364\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.8335 - accuracy: 0.7523 - val_loss: 0.6580 - val_accuracy: 0.8273\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.8501 - accuracy: 0.7432 - val_loss: 0.6398 - val_accuracy: 0.8364\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.7926 - accuracy: 0.7674 - val_loss: 0.6256 - val_accuracy: 0.8409\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.7881 - accuracy: 0.7583 - val_loss: 0.6120 - val_accuracy: 0.8364\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.7846 - accuracy: 0.7591 - val_loss: 0.6042 - val_accuracy: 0.8455\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7665 - accuracy: 0.7811 - val_loss: 0.5845 - val_accuracy: 0.8432\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.7742 - accuracy: 0.7500 - val_loss: 0.5768 - val_accuracy: 0.8636\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.7370 - accuracy: 0.7682 - val_loss: 0.5697 - val_accuracy: 0.8500\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.7366 - accuracy: 0.7667 - val_loss: 0.5574 - val_accuracy: 0.8568\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.7265 - accuracy: 0.7765 - val_loss: 0.5542 - val_accuracy: 0.8477\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6986 - accuracy: 0.7811 - val_loss: 0.5506 - val_accuracy: 0.8500\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.7818 - val_loss: 0.5462 - val_accuracy: 0.8432\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6964 - accuracy: 0.7833 - val_loss: 0.5199 - val_accuracy: 0.8705\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.7803 - val_loss: 0.5144 - val_accuracy: 0.8614\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6760 - accuracy: 0.7992 - val_loss: 0.5231 - val_accuracy: 0.8545\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6650 - accuracy: 0.7985 - val_loss: 0.5085 - val_accuracy: 0.8477\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6445 - accuracy: 0.8023 - val_loss: 0.5140 - val_accuracy: 0.8568\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6426 - accuracy: 0.7871 - val_loss: 0.4793 - val_accuracy: 0.8682\n",
            "Epoch 50/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6275 - accuracy: 0.8015 - val_loss: 0.4793 - val_accuracy: 0.8523\n",
            "Epoch 51/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6249 - accuracy: 0.8136 - val_loss: 0.4761 - val_accuracy: 0.8659\n",
            "Epoch 52/100\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.6495 - accuracy: 0.7962 - val_loss: 0.4777 - val_accuracy: 0.8614\n",
            "Epoch 53/100\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.6256 - accuracy: 0.8008 - val_loss: 0.4546 - val_accuracy: 0.8909\n",
            "Epoch 54/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6157 - accuracy: 0.8023 - val_loss: 0.4626 - val_accuracy: 0.8659\n",
            "Epoch 55/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5969 - accuracy: 0.8068 - val_loss: 0.4507 - val_accuracy: 0.8750\n",
            "Epoch 56/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5854 - accuracy: 0.8174 - val_loss: 0.4466 - val_accuracy: 0.8614\n",
            "Epoch 57/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5996 - accuracy: 0.8083 - val_loss: 0.4494 - val_accuracy: 0.8614\n",
            "Epoch 58/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.6152 - accuracy: 0.7932 - val_loss: 0.4457 - val_accuracy: 0.8614\n",
            "Epoch 59/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5932 - accuracy: 0.8159 - val_loss: 0.4317 - val_accuracy: 0.8727\n",
            "Epoch 60/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5695 - accuracy: 0.8212 - val_loss: 0.4205 - val_accuracy: 0.8773\n",
            "Epoch 61/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5692 - accuracy: 0.8121 - val_loss: 0.4180 - val_accuracy: 0.8795\n",
            "Epoch 62/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5689 - accuracy: 0.8212 - val_loss: 0.4206 - val_accuracy: 0.8727\n",
            "Epoch 63/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5818 - accuracy: 0.8030 - val_loss: 0.4217 - val_accuracy: 0.8705\n",
            "Epoch 64/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5727 - accuracy: 0.8189 - val_loss: 0.4225 - val_accuracy: 0.8886\n",
            "Epoch 65/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5894 - accuracy: 0.8205 - val_loss: 0.4163 - val_accuracy: 0.8705\n",
            "Epoch 66/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5572 - accuracy: 0.8091 - val_loss: 0.4094 - val_accuracy: 0.8886\n",
            "Epoch 67/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5552 - accuracy: 0.8212 - val_loss: 0.4009 - val_accuracy: 0.8955\n",
            "Epoch 68/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5569 - accuracy: 0.8220 - val_loss: 0.4000 - val_accuracy: 0.8773\n",
            "Epoch 69/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.8273 - val_loss: 0.3931 - val_accuracy: 0.8705\n",
            "Epoch 70/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.8227 - val_loss: 0.3948 - val_accuracy: 0.8864\n",
            "Epoch 71/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5162 - accuracy: 0.8424 - val_loss: 0.3920 - val_accuracy: 0.8727\n",
            "Epoch 72/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5387 - accuracy: 0.8258 - val_loss: 0.3824 - val_accuracy: 0.8932\n",
            "Epoch 73/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5036 - accuracy: 0.8295 - val_loss: 0.3652 - val_accuracy: 0.8932\n",
            "Epoch 74/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.8235 - val_loss: 0.3888 - val_accuracy: 0.9023\n",
            "Epoch 75/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5298 - accuracy: 0.8242 - val_loss: 0.3743 - val_accuracy: 0.8864\n",
            "Epoch 76/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.5250 - accuracy: 0.8356 - val_loss: 0.3884 - val_accuracy: 0.8795\n",
            "Epoch 77/100\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4984 - accuracy: 0.8356 - val_loss: 0.3665 - val_accuracy: 0.8955\n",
            "Epoch 78/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4898 - accuracy: 0.8394 - val_loss: 0.3659 - val_accuracy: 0.8864\n",
            "Epoch 79/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5198 - accuracy: 0.8258 - val_loss: 0.3592 - val_accuracy: 0.9000\n",
            "Epoch 80/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4800 - accuracy: 0.8477 - val_loss: 0.3635 - val_accuracy: 0.8955\n",
            "Epoch 81/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.8492 - val_loss: 0.3732 - val_accuracy: 0.8864\n",
            "Epoch 82/100\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4913 - accuracy: 0.8409 - val_loss: 0.3678 - val_accuracy: 0.8909\n",
            "Epoch 83/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.8303 - val_loss: 0.3627 - val_accuracy: 0.8841\n",
            "Epoch 84/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.8432 - val_loss: 0.3630 - val_accuracy: 0.8864\n",
            "Epoch 85/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4792 - accuracy: 0.8508 - val_loss: 0.3624 - val_accuracy: 0.8977\n",
            "Epoch 86/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.8379 - val_loss: 0.3471 - val_accuracy: 0.8955\n",
            "Epoch 87/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.8333 - val_loss: 0.3527 - val_accuracy: 0.9091\n",
            "Epoch 88/100\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4837 - accuracy: 0.8439 - val_loss: 0.3477 - val_accuracy: 0.8932\n",
            "Epoch 89/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.8485 - val_loss: 0.3422 - val_accuracy: 0.8886\n",
            "Epoch 90/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.8553 - val_loss: 0.3583 - val_accuracy: 0.8705\n",
            "Epoch 91/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4780 - accuracy: 0.8311 - val_loss: 0.3360 - val_accuracy: 0.9068\n",
            "Epoch 92/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.8538 - val_loss: 0.3251 - val_accuracy: 0.9091\n",
            "Epoch 93/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.8614 - val_loss: 0.3318 - val_accuracy: 0.8955\n",
            "Epoch 94/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.8470 - val_loss: 0.3267 - val_accuracy: 0.9045\n",
            "Epoch 95/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.8545 - val_loss: 0.3294 - val_accuracy: 0.8932\n",
            "Epoch 96/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.8447 - val_loss: 0.3348 - val_accuracy: 0.8864\n",
            "Epoch 97/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.8576 - val_loss: 0.3299 - val_accuracy: 0.8955\n",
            "Epoch 98/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.8598 - val_loss: 0.3353 - val_accuracy: 0.8841\n",
            "Epoch 99/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8644 - val_loss: 0.3266 - val_accuracy: 0.8977\n",
            "Epoch 100/100\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.8341 - val_loss: 0.3276 - val_accuracy: 0.8955\n",
            "peak memory: 2470.10 MiB, increment: 0.08 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbAq_rEeVwuH"
      },
      "source": [
        "**Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux3SAloSVyiG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c412bcb6-6a89-4454-edec-790b06bcf164"
      },
      "source": [
        "start = time.time()\n",
        "%memit test_metrics = model.evaluate(X_test, Y_test)\n",
        "end = time.time()\n",
        "\n",
        "FLAGS_times['evaluating'] = end - start\n",
        "\n",
        "test_metrics_dict = {}\n",
        "for name, val in zip(model.metrics_names, test_metrics):\n",
        "  print('{}: {:0.4f}'.format(name, val), flush=True)\n",
        "  test_metrics_dict[name] = val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3887 - accuracy: 0.8818\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3887 - accuracy: 0.8818\n",
            "peak memory: 2470.05 MiB, increment: 0.20 MiB\n",
            "loss: 0.3887\n",
            "accuracy: 0.8818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPh4ll_6VjsF"
      },
      "source": [
        "**Predicting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzNtToDNVof8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb44fb8d-7b58-4994-b4b1-147b5c45b3ed"
      },
      "source": [
        "start = time.time()\n",
        "%memit predicted = model.predict(X_test)\n",
        "end = time.time()\n",
        "\n",
        "FLAGS_times['predicting'] = end - start"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peak memory: 2470.04 MiB, increment: 0.00 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nV6j4cCVTS4"
      },
      "source": [
        "**Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ4TtOgWVVoz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a323a7c-5e96-4d14-b5ec-622ec76e1a7a"
      },
      "source": [
        "pred_y = predicted.argmax(axis=-1)\n",
        "\n",
        "cm = confusion_matrix(Y_test, pred_y)\n",
        "print('Confusion matrix')\n",
        "print(cm)\n",
        "\n",
        "cr = classification_report(Y_test, pred_y)\n",
        "print('\\n\\nClassification report')\n",
        "print(cr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix\n",
            "[[45  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 22  0  0  1  0  8  0  0  0  1]\n",
            " [ 0  0 38  0  1  0  0  0  2  0  0]\n",
            " [ 0  0  0 43  0  0  0  0  0  0  0]\n",
            " [ 0  2  0  0 40  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0 33  0  0  0  0  0]\n",
            " [ 0 16  0  0  0  0 18  0  0  0  1]\n",
            " [ 0  0  0  0  0  0  0 42  0  0  0]\n",
            " [ 0  0  9  0  2  0  0  1 31  1  0]\n",
            " [ 0  0  2  0  1  0  0  0  2 39  0]\n",
            " [ 0  2  0  0  0  0  0  1  0  0 35]]\n",
            "\n",
            "\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        45\n",
            "           1       0.51      0.69      0.59        32\n",
            "           2       0.78      0.93      0.84        41\n",
            "           3       1.00      1.00      1.00        43\n",
            "           4       0.89      0.95      0.92        42\n",
            "           5       1.00      0.97      0.99        34\n",
            "           6       0.69      0.51      0.59        35\n",
            "           7       0.95      1.00      0.98        42\n",
            "           8       0.89      0.70      0.78        44\n",
            "           9       0.97      0.89      0.93        44\n",
            "          10       0.95      0.92      0.93        38\n",
            "\n",
            "    accuracy                           0.88       440\n",
            "   macro avg       0.88      0.87      0.87       440\n",
            "weighted avg       0.89      0.88      0.88       440\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27YlDA5XjE9c"
      },
      "source": [
        "**Store the results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFpbdBcrjIvI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ace71de-3da4-46e6-a15f-ce6ea145b788"
      },
      "source": [
        "if FLAGS_store_results:\n",
        "  os.makedirs(FLAGS_results_directory, exist_ok=True)   \n",
        "\n",
        "  #\n",
        "  # Store the results\n",
        "  #\n",
        "\n",
        "  # History\n",
        "  fout = open('{}/history.yaml'.format(FLAGS_results_directory), 'w')\n",
        "  yl.dump(history.history, fout)\n",
        "  fout.close()\n",
        "\n",
        "  # Test metrics\n",
        "  fout = open('{}/test_metrics.yaml'.format(FLAGS_results_directory), 'w')\n",
        "  yl.dump(test_metrics_dict, fout)\n",
        "  fout.close()\n",
        "\n",
        "  # Dataset\n",
        "  np.savez_compressed('{}/y_train.npz'.format(FLAGS_results_directory), values=Y_train)\n",
        "  np.savez_compressed('{}/y_val.npz'.format(FLAGS_results_directory), values=Y_val)\n",
        "  np.savez_compressed('{}/y_test.npz'.format(FLAGS_results_directory), values=Y_test)\n",
        "\n",
        "  # Predicted\n",
        "  np.savez_compressed('{}/predicted'.format(FLAGS_results_directory), values=predicted)\n",
        "\n",
        "  # Confusion matrix\n",
        "  np.savez_compressed('{}/confusion_matrix'.format(FLAGS_results_directory), values=cm)\n",
        "\n",
        "  # Classification report\n",
        "  fout = open('{}/classification_report.pk'.format(FLAGS_results_directory), 'wb')\n",
        "  pk.dump(cr, fout)\n",
        "  fout.close()\n",
        "\n",
        "  # Time\n",
        "  fout = open('{}/elapsed_time.yaml'.format(FLAGS_results_directory), 'w')\n",
        "  print(FLAGS_times)\n",
        "  yl.dump(FLAGS_times, fout)\n",
        "  fout.close()\n",
        "          \n",
        "  # gpu.log\n",
        "  command = 'cp gpu.log \"{}\"'.format(FLAGS_results_directory)\n",
        "  !$command      \n",
        "\n",
        "  #\n",
        "  # Store the hadware specifications\n",
        "  #\n",
        "\n",
        "  spec, _ = execute(\"nvidia-smi\")\n",
        "  filename = '{}/nvidia-smi.txt'.format(FLAGS_results_directory)\n",
        "  save(filename, spec)\n",
        "\n",
        "  spec, _ = execute(\"cat /proc/cpuinfo\")\n",
        "  filename = '{}/cpuinfo.txt'.format(FLAGS_results_directory)\n",
        "  save(filename, spec)\n",
        "\n",
        "  spec, _ = execute(\"cat /proc/meminfo\")\n",
        "  filename = '{}/meminfo.txt'.format(FLAGS_results_directory)\n",
        "  save(filename, spec)  \n",
        "\n",
        "  #\n",
        "  # Store the model\n",
        "  #\n",
        "  if FLAGS_store_model:\n",
        "    directory = '{}/model'.format(FLAGS_results_directory)\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "    model.save(directory)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'loading': 1.6365668773651123, 'training': 18.246812105178833, 'evaluating': 0.7854611873626709, 'predicting': 0.5899162292480469}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md7qDdRHiubJ"
      },
      "source": [
        "**Free the memory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCVYdx2ii1Px"
      },
      "source": [
        "del X\n",
        "del Y\n",
        "del X_train\n",
        "del X_val\n",
        "del X_test\n",
        "del Y_train\n",
        "del Y_val\n",
        "del Y_test\n",
        "del model\n",
        "del history\n",
        "del test_metrics\n",
        "del test_metrics_dict\n",
        "del predicted\n",
        "del cm\n",
        "del cr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQPhDT5CGIp-"
      },
      "source": [
        "**Flush Google Driver**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4qPqfYXetkJ"
      },
      "source": [
        "if FLAGS_store_results:\n",
        "  #\n",
        "  # Flush the Driver\n",
        "  #\n",
        "  drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-HdUj-JGzR0"
      },
      "source": [
        "**Remove the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRjs3ohmG4Gj"
      },
      "source": [
        "# Kill gpu_usage\n",
        "!pid=`ps -aux |grep gpu_usage.sh | awk '{print $2}' | head -n 1` ; kill -9 $pid\n",
        "\n",
        "# Clean\n",
        "command = 'rm -rf {}* gpu.log gpu_usage.sh graphs-number-of-nodes.yaml'.format(FLAGS_sequence)\n",
        "!$command"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXVZV-rmifUX"
      },
      "source": [
        "**Finish**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj_NvS_7Hv03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf22ef2-b947-4e93-88fa-4d19feaee858"
      },
      "source": [
        "for key, value in FLAGS_times.items():\n",
        "    print(key, value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading 1.6365668773651123\n",
            "training 18.246812105178833\n",
            "evaluating 0.7854611873626709\n",
            "predicting 0.5899162292480469\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}